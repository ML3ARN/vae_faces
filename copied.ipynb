{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbb76dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "# from tensorflow_probability  import distributions as tfd\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import Layer, Input, Conv2D, Dense, Flatten, Reshape, Lambda, Dropout\n",
    "from tensorflow.keras.layers import Conv2DTranspose, MaxPooling2D, UpSampling2D, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime, os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from packaging.version import parse as parse_version\n",
    "assert parse_version(tf.__version__) < parse_version(\"2.4.0\"), \\\n",
    "    f\"Please install TensorFlow version 2.3.1 or older. Your current version is {tf.__version__}.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7daf4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test_), ds_info = tfds.load('celeb_a', \n",
    "                              split=['train', 'test'], \n",
    "                              shuffle_files=True,\n",
    "                              with_info=True, data_dir='/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8812da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "def preprocess(sample):\n",
    "    image = sample['image']\n",
    "    image = tf.image.resize(image, [112,112])\n",
    "    image = tf.cast(image, tf.float32)/255.\n",
    "    return image, image\n",
    "\n",
    "ds_train = ds_train.map(preprocess)\n",
    "ds_train = ds_train.shuffle(batch_size*4)\n",
    "ds_train = ds_train.batch(batch_size).prefetch(batch_size)\n",
    "\n",
    "ds_test = ds_test_.map(preprocess).batch(batch_size).prefetch(batch_size)\n",
    "\n",
    "train_num = ds_info.splits['train'].num_examples\n",
    "test_num = ds_info.splits['test'].num_examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b793f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianSampling(Layer):        \n",
    "    def call(self, inputs):\n",
    "        means, logvar = inputs\n",
    "        epsilon = tf.random.normal(shape=tf.shape(means), mean=0., stddev=1.)\n",
    "        samples = means + tf.exp(0.5*logvar)*epsilon\n",
    "\n",
    "        return samples\n",
    "    \n",
    "class DownConvBlock(Layer):\n",
    "    count = 0\n",
    "    def __init__(self, filters, kernel_size=(3,3), strides=1, padding='same'):\n",
    "        super(DownConvBlock, self).__init__(name=f\"DownConvBlock_{DownConvBlock.count}\")\n",
    "        DownConvBlock.count+=1\n",
    "        self.forward = Sequential([Conv2D(filters, kernel_size, strides, padding)])\n",
    "        self.forward.add(BatchNormalization())\n",
    "        self.forward.add(layers.LeakyReLU(0.2))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.forward(inputs)\n",
    "\n",
    "class UpConvBlock(Layer):\n",
    "    count = 0\n",
    "    def __init__(self, filters, kernel_size=(3,3), padding='same'):\n",
    "        super(UpConvBlock, self).__init__(name=f\"UpConvBlock_{UpConvBlock.count}\")\n",
    "        UpConvBlock.count += 1\n",
    "        self.forward = Sequential([Conv2D(filters, kernel_size, 1, padding),])\n",
    "        self.forward.add(layers.LeakyReLU(0.2))\n",
    "        self.forward.add(UpSampling2D((2,2)))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.forward(inputs)\n",
    "    \n",
    "class Encoder(Layer):\n",
    "    def __init__(self, z_dim, name='encoder'):\n",
    "        super(Encoder, self).__init__(name=name)\n",
    "        \n",
    "        self.features_extract = Sequential([\n",
    "            DownConvBlock(filters = 32, kernel_size=(3,3), strides=2),\n",
    "            DownConvBlock(filters = 32, kernel_size=(3,3), strides=2),\n",
    "            DownConvBlock(filters = 64, kernel_size=(3,3), strides=2),\n",
    "            DownConvBlock(filters = 64, kernel_size=(3,3), strides=2),\n",
    "            Flatten()])\n",
    "        \n",
    "        self.dense_mean = Dense(z_dim, name='mean')\n",
    "        self.dense_logvar = Dense(z_dim, name='logvar')\n",
    "        self.sampler = GaussianSampling()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.features_extract(inputs)\n",
    "        mean = self.dense_mean(x)\n",
    "        logvar = self.dense_logvar(x)\n",
    "        z = self.sampler([mean, logvar])\n",
    "        return z, mean, logvar\n",
    "\n",
    "class Decoder(Layer):\n",
    "    def __init__(self, z_dim, name='decoder'):\n",
    "        super(Decoder, self).__init__(name=name)\n",
    "            \n",
    "        self.forward = Sequential([\n",
    "                        Dense(7*7*64, activation='relu'),\n",
    "                        Reshape((7,7,64)),\n",
    "                        UpConvBlock(filters=64, kernel_size=(3,3)),\n",
    "                        UpConvBlock(filters=64, kernel_size=(3,3)),\n",
    "                        UpConvBlock(filters=32, kernel_size=(3,3)),\n",
    "                        UpConvBlock(filters=32, kernel_size=(3,3)),\n",
    "                        Conv2D(filters=3, kernel_size=(3,3), strides=1, padding='same', activation='sigmoid'),\n",
    "                \n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.forward(inputs)\n",
    "\n",
    "    \n",
    "class VAE(Model):\n",
    "    def __init__(self, z_dim, name='VAE'):\n",
    "        super(VAE, self).__init__(name=name)\n",
    "        self.encoder = Encoder(z_dim)\n",
    "        self.decoder = Decoder(z_dim)\n",
    "        self.mean = None\n",
    "        self.logvar = None\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        z, self.mean, self.logvar = self.encoder(inputs)\n",
    "        out = self.decoder(z)           \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be9bdbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(z_dim=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90e4d77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_kl_loss(y_true, y_pred):\n",
    "    kl_loss =  - 0.5 * tf.reduce_mean(1 + vae.logvar - tf.square(vae.mean) - tf.exp(vae.logvar))\n",
    "    return kl_loss    \n",
    "\n",
    "def vae_rc_loss(y_true, y_pred):\n",
    "    #rc_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    rc_loss = tf.keras.losses.MSE(y_true, y_pred)\n",
    "    return rc_loss\n",
    "\n",
    "def vae_loss(y_true, y_pred):\n",
    "    kl_loss = vae_kl_loss(y_true, y_pred)\n",
    "    rc_loss = vae_rc_loss(y_true, y_pred)\n",
    "    kl_weight_const = 0.01\n",
    "    return kl_weight_const*kl_loss + rc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5010aad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node VAE/encoder/sequential_4/DownConvBlock_0/sequential/conv2d/Conv2D (defined at <ipython-input-7-b392740aaf94>:19) ]] [Op:__inference_train_function_4107]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node VAE/encoder/sequential_4/DownConvBlock_0/sequential/conv2d/Conv2D:\n IteratorGetNext (defined at <ipython-input-10-967ff380b52c>:31)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-967ff380b52c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m history = vae.fit(ds_train, validation_data=ds_test,\n\u001b[0;32m---> 31\u001b[0;31m                 epochs = 20, callbacks = callbacks_list)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node VAE/encoder/sequential_4/DownConvBlock_0/sequential/conv2d/Conv2D (defined at <ipython-input-7-b392740aaf94>:19) ]] [Op:__inference_train_function_4107]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node VAE/encoder/sequential_4/DownConvBlock_0/sequential/conv2d/Conv2D:\n IteratorGetNext (defined at <ipython-input-10-967ff380b52c>:31)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model_path = \"./models/my_vae_celeb_a.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_path, \n",
    "                             monitor= \"vae_rc_loss\", \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode= \"auto\", \n",
    "                             save_weights_only = True)\n",
    "\n",
    "early = EarlyStopping(monitor= \"vae_rc_loss\", \n",
    "                      mode= \"auto\", \n",
    "                      patience = 3)\n",
    "\n",
    "callbacks_list = [checkpoint, early]\n",
    "\n",
    "initial_learning_rate = 1e-3\n",
    "steps_per_epoch = int(np.round(train_num/batch_size))\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=steps_per_epoch,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "vae.compile(\n",
    "    loss = [vae_loss],\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=3e-3),\n",
    "    metrics=[vae_kl_loss,vae_rc_loss])\n",
    "\n",
    "\n",
    "history = vae.fit(ds_train, validation_data=ds_test,\n",
    "                epochs = 20, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd1480a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
